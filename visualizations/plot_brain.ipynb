{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting with ``mne.viz.Brain``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Use the sample data which is data from a subject being presented auditory and visual stimuli to display the functionality\n",
    "of `mne.viz.Brain` for plotting data on a brain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import os.path as op\n",
    "sys.path.append(\"../\")\n",
    "from mne_path import PathHandler\n",
    "from glob import glob\n",
    "ph = PathHandler()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Changed to:  /Users/jonghang/mne_data/MNE-sample-data\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_DATA_DIR = ph.cddir(ph.SAMPLE_DIR)\n",
    "\n",
    "subjects_dir = op.join(SAMPLE_DATA_DIR, 'subjects')\n",
    "sample_dir = op.join(SAMPLE_DATA_DIR, 'MEG', 'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add source information\n",
    "\n",
    "### Plot Basic Source Information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain_kwargs = dict(alpha=0.1, background='white', cortex='low_contrast')\n",
    "\n",
    "brain = mne.viz.Brain('sample', \n",
    "                      subjects_dir =subjects_dir, **brain_kwargs)\n",
    "\n",
    "stc = mne.read_source_estimate(op.join(sample_dir, 'sample_audvis-meg'))\n",
    "\n",
    "stc.crop(0.09, 0.1)\n",
    "\n",
    "kwargs = dict(fmin=stc.data.min(), fmax=stc.data.max(), alpha=0.25,\n",
    "              smoothing_steps='nearest', time=stc.times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add LH and RH to Basic Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Previous Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "del brain\n",
    "del stc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain_kwargs = dict(alpha=0.1, background='white', \n",
    "                    cortex='low_contrast')\n",
    "\n",
    "brain = mne.viz.Brain('sample', \n",
    "                      subjects_dir = subjects_dir, \n",
    "                      **brain_kwargs)\n",
    "\n",
    "stc = mne.read_source_estimate(op.join(sample_dir, 'sample_audvis-meg'))\n",
    "\n",
    "stc.crop(0.09, 0.1)\n",
    "\n",
    "kwargs = dict(fmin = stc.data.min(), \n",
    "              fmax = stc.data.max(), alpha=0.25,\n",
    "              smoothing_steps = 'nearest', \n",
    "              time = stc.times,\n",
    "              time_label_size = 5)\n",
    "COLORBAR_KWARGS = dict(title_font_size=20, \n",
    "                       font_size=10)\n",
    "\n",
    "brain.add_data(stc.lh_data, \n",
    "               hemi = 'lh', \n",
    "               vertices = stc.lh_vertno,\n",
    "               colorbar=True,\n",
    "               # colorbar_kwargs = COLORBAR_KWARGS,\n",
    "               **kwargs)\n",
    "\n",
    "brain.add_data(stc.rh_data, \n",
    "               hemi = 'rh', \n",
    "               vertices = stc.rh_vertno,\n",
    "               colorbar=True,\n",
    "               # colorbar_kwargs = COLORBAR_KWARGS,\n",
    "               **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method add_data in module mne.viz._brain._brain:\n",
      "\n",
      "add_data(array, fmin=None, fmid=None, fmax=None, thresh=None, center=None, transparent=False, colormap='auto', alpha=1, vertices=None, smoothing_steps=None, time=None, time_label='auto', colorbar=True, hemi=None, remove_existing=None, time_label_size=None, initial_time=None, scale_factor=None, vector_alpha=None, clim=None, src=None, volume_options=0.4, colorbar_kwargs=None, verbose=None) method of mne.viz._brain._brain.Brain instance\n",
      "    Display data from a numpy array on the surface or volume.\n",
      "    \n",
      "    This provides a similar interface to\n",
      "    :meth:`surfer.Brain.add_overlay`, but it displays\n",
      "    it with a single colormap. It offers more flexibility over the\n",
      "    colormap, and provides a way to display four-dimensional data\n",
      "    (i.e., a timecourse) or five-dimensional data (i.e., a\n",
      "    vector-valued timecourse).\n",
      "    \n",
      "    .. note:: ``fmin`` sets the low end of the colormap, and is separate\n",
      "              from thresh (this is a different convention from\n",
      "              :meth:`surfer.Brain.add_overlay`).\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    array : numpy array, shape (n_vertices[, 3][, n_times])\n",
      "        Data array. For the data to be understood as vector-valued\n",
      "        (3 values per vertex corresponding to X/Y/Z surface RAS),\n",
      "        then ``array`` must be have all 3 dimensions.\n",
      "        If vectors with no time dimension are desired, consider using a\n",
      "        singleton (e.g., ``np.newaxis``) to create a \"time\" dimension\n",
      "        and pass ``time_label=None`` (vector values are not supported).\n",
      "    \n",
      "    fmin : float\n",
      "        Minimum value in colormap (uses real fmin if None).\n",
      "    fmid : float\n",
      "        Intermediate value in colormap (fmid between fmin and\n",
      "        fmax if None).\n",
      "    fmax : float\n",
      "        Maximum value in colormap (uses real max if None).\n",
      "    \n",
      "    thresh : None or float\n",
      "        Not supported yet.\n",
      "        If not None, values below thresh will not be visible.\n",
      "    \n",
      "    center : float or None\n",
      "        If not None, center of a divergent colormap, changes the meaning of\n",
      "        fmin, fmax and fmid.\n",
      "    \n",
      "    transparent : bool | None\n",
      "        If True: use a linear transparency between fmin and fmid\n",
      "        and make values below fmin fully transparent (symmetrically for\n",
      "        divergent colormaps). None will choose automatically based on colormap\n",
      "        type.\n",
      "    colormap : str, list of color, or array\n",
      "        Name of matplotlib colormap to use, a list of matplotlib colors,\n",
      "        or a custom look up table (an n x 4 array coded with RBGA values\n",
      "        between 0 and 255), the default \"auto\" chooses a default divergent\n",
      "        colormap, if \"center\" is given (currently \"icefire\"), otherwise a\n",
      "        default sequential colormap (currently \"rocket\").\n",
      "    alpha : float in [0, 1]\n",
      "        Alpha level to control opacity of the overlay.\n",
      "    vertices : numpy array\n",
      "        Vertices for which the data is defined (needed if\n",
      "        ``len(data) < nvtx``).\n",
      "    smoothing_steps : int or None\n",
      "        Number of smoothing steps (smoothing is used if len(data) < nvtx)\n",
      "        The value 'nearest' can be used too. None (default) will use as\n",
      "        many as necessary to fill the surface.\n",
      "    time : numpy array\n",
      "        Time points in the data array (if data is 2D or 3D).\n",
      "    \n",
      "    time_label : str | callable | None\n",
      "        Format of the time label (a format string, a function that maps\n",
      "        floating point time values to strings, or None for no label). The\n",
      "        default is ``'auto'``, which will use ``time=%0.2f ms`` if there\n",
      "        is more than one time point.\n",
      "    colorbar : bool\n",
      "        Whether to add a colorbar to the figure. Can also be a tuple\n",
      "        to give the (row, col) index of where to put the colorbar.\n",
      "    hemi : str | None\n",
      "        If None, it is assumed to belong to the hemisphere being\n",
      "        shown. If two hemispheres are being shown, an error will\n",
      "        be thrown.\n",
      "    remove_existing : bool\n",
      "        Not supported yet.\n",
      "        Remove surface added by previous \"add_data\" call. Useful for\n",
      "        conserving memory when displaying different data in a loop.\n",
      "    time_label_size : int\n",
      "        Font size of the time label (default 14).\n",
      "    initial_time : float | None\n",
      "        Time initially shown in the plot. ``None`` to use the first time\n",
      "        sample (default).\n",
      "    scale_factor : float | None (default)\n",
      "        The scale factor to use when displaying glyphs for vector-valued\n",
      "        data.\n",
      "    vector_alpha : float | None\n",
      "        Alpha level to control opacity of the arrows. Only used for\n",
      "        vector-valued data. If None (default), ``alpha`` is used.\n",
      "    clim : dict\n",
      "        Original clim arguments.\n",
      "    \n",
      "    src : instance of SourceSpaces | None\n",
      "        The source space corresponding to the source estimate. Only necessary\n",
      "        if the STC is a volume or mixed source estimate.\n",
      "    volume_options : float | dict | None\n",
      "        Options for volumetric source estimate plotting, with key/value pairs:\n",
      "    \n",
      "        - ``'resolution'`` : float | None\n",
      "            Resolution (in mm) of volume rendering. Smaller (e.g., 1.) looks\n",
      "            better at the cost of speed. None (default) uses the volume source\n",
      "            space resolution, which is often something like 7 or 5 mm,\n",
      "            without resampling.\n",
      "        - ``'blending'`` : str\n",
      "            Can be \"mip\" (default) for :term:`maximum intensity projection` or\n",
      "            \"composite\" for composite blending using alpha values.\n",
      "        - ``'alpha'`` : float | None\n",
      "            Alpha for the volumetric rendering. Defaults are 0.4 for vector source\n",
      "            estimates and 1.0 for scalar source estimates.\n",
      "        - ``'surface_alpha'`` : float | None\n",
      "            Alpha for the surface enclosing the volume(s). None (default) will use\n",
      "            half the volume alpha. Set to zero to avoid plotting the surface.\n",
      "        - ``'silhouette_alpha'`` : float | None\n",
      "            Alpha for a silhouette along the outside of the volume. None (default)\n",
      "            will use ``0.25 * surface_alpha``.\n",
      "        - ``'silhouette_linewidth'`` : float\n",
      "            The line width to use for the silhouette. Default is 2.\n",
      "    \n",
      "        A float input (default 1.) or None will be used for the ``'resolution'``\n",
      "        entry.\n",
      "    colorbar_kwargs : dict | None\n",
      "        Options to pass to :meth:`pyvista.Plotter.add_scalar_bar`\n",
      "        (e.g., ``dict(title_font_size=10)``).\n",
      "    \n",
      "    verbose : bool | str | int | None\n",
      "        Control verbosity of the logging output. If ``None``, use the default\n",
      "        verbosity level. See the :ref:`logging documentation <tut-logging>` and\n",
      "        :func:`mne.verbose` for details. Should only be passed as a keyword\n",
      "        argument.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    If the data is defined for a subset of vertices (specified\n",
      "    by the \"vertices\" parameter), a smoothing method is used to interpolate\n",
      "    the data onto the high resolution surface. If the data is defined for\n",
      "    subsampled version of the surface, smoothing_steps can be set to None,\n",
      "    in which case only as many smoothing steps are applied until the whole\n",
      "    surface is filled with non-zeros.\n",
      "    \n",
      "    Due to a VTK alpha rendering bug, ``vector_alpha`` is\n",
      "    clamped to be strictly < 1.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# help(mne.viz.Brain)\n",
    "help(brain.add_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the view of the brain\n",
    "\n",
    "Adjust the view of the brain using ``show_view`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain('sample', subjects_dir=subjects_dir, **brain_kwargs)\n",
    "brain.show_view(azimuth=190, elevation=70, distance=350, focalpoint=(0, 0, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight a region on the brain\n",
    "\n",
    "* o highlight a region of the brain for analyses use the ``add_label`` method.\n",
    "* Labels are stored in the Freesurfer label directory from the `recon-all` for that subject\n",
    "* Labels can also be made following the [Freesurfer instructions](https://surfer.nmr.mgh.harvard.edu/fswiki/mri_vol2label)\n",
    "* In this example, Brodmann Area 44 is shown\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The MNE sample dataset contains only a subselection of the\n",
    "          Freesurfer labels created during the ``recon-all``.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain('sample', subjects_dir=subjects_dir, **brain_kwargs)\n",
    "brain.add_label('BA44', hemi='lh', color='green', borders=True)\n",
    "brain.show_view(azimuth=190, elevation=70, distance=350, focalpoint=(0, 0, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include the Head in Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain('sample', subjects_dir=subjects_dir, **brain_kwargs)\n",
    "brain.add_head(alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Sensors Positions\n",
    "\n",
    "Put the sensors into context the data that generated the source time course (STC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain('sample', subjects_dir=subjects_dir, **brain_kwargs)\n",
    "evoked = mne.read_evokeds(op.join(sample_dir, 'sample_audvis-ave.fif'))[0]\n",
    "trans = mne.read_trans(op.join(sample_dir, 'sample_audvis_raw-trans.fif'))\n",
    "brain.add_sensors(evoked.info, trans)\n",
    "brain.show_view(distance=500)  # move back to show sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add current dipoles\n",
    "\n",
    "Dipole modeling as in `tut-dipole-orientations` can be plotted on the\n",
    "brain as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain('sample', subjects_dir=subjects_dir, **brain_kwargs)\n",
    "dip = mne.read_dipole(op.join(sample_dir, 'sample_audvis_set1.dip'))\n",
    "cmap = plt.colormaps['YlOrRd']\n",
    "colors = [cmap(gof / dip.gof.max()) for gof in dip.gof]\n",
    "brain.add_dipole(dip, trans, colors=colors, scales=list(dip.amplitude * 1e8))\n",
    "brain.show_view(azimuth=-20, elevation=60, distance=300)\n",
    "img = brain.screenshot()  # for next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a screenshot for exporting the brain image\n",
    "Also, we can a static image of the brain using ``screenshot`` (above),\n",
    "which will allow us to add a colorbar. This is useful for figures in\n",
    "publications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "cax = fig.add_axes([0.9, 0.1, 0.05, 0.8])\n",
    "norm = Normalize(vmin=0, vmax=dip.gof.max())\n",
    "fig.colorbar(ScalarMappable(norm=norm, cmap=cmap), cax=cax)\n",
    "fig.suptitle('Dipole Fits Scaled by Amplitude and Colored by GOF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Authors: SIONG Jong Hang \n",
    "         jonghang@gmail.com\n",
    "         Alex Rockhill\n",
    "         aprockhill@mailbox.org\n",
    "\n",
    "License: BSD-3-Clause\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

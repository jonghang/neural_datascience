{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting with ``mne.viz.Brain``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Use the sample data which is data from a subject being presented auditory and visual stimuli to display the functionality\n",
    "of `mne.viz.Brain` for plotting data on a brain.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import os.path as op\n",
    "sys.path.append(\"../\")\n",
    "from mne_path import PathHandler\n",
    "ph = PathHandler()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import ScalarMappable\n",
    "from matplotlib.colors import Normalize\n",
    "\n",
    "import mne\n",
    "from mne.datasets import sample\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SAMPLE_DATA_DIR = ph.cddir(ph.SAMPLE_DIR)\n",
    "\n",
    "subjects_dir = op.join(SAMPLE_DATA_DIR, 'subjects')\n",
    "sample_dir = op.join(SAMPLE_DATA_DIR, 'MEG', 'sample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add source information\n",
    "\n",
    "Plot source information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain_kwargs = dict(alpha=0.1, background='white', cortex='low_contrast')\n",
    "\n",
    "brain = mne.viz.Brain('sample', \n",
    "                      subjects_dir =subjects_dir, **brain_kwargs)\n",
    "\n",
    "stc = mne.read_source_estimate(op.join(sample_dir, 'sample_audvis-meg'))\n",
    "\n",
    "stc.crop(0.09, 0.1)\n",
    "\n",
    "kwargs = dict(fmin=stc.data.min(), fmax=stc.data.max(), alpha=0.25,\n",
    "              smoothing_steps='nearest', time=stc.times)\n",
    "\n",
    "brain.add_data(stc.lh_data, \n",
    "               hemi = 'lh', \n",
    "               vertices = stc.lh_vertno,\n",
    "               **kwargs)\n",
    "\n",
    "brain.add_data(stc.rh_data, \n",
    "               hemi = 'rh', \n",
    "               vertices = stc.rh_vertno, \n",
    "               **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify the view of the brain\n",
    "\n",
    "Adjust the view of the brain using ``show_view`` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain('sample', subjects_dir=subjects_dir, **brain_kwargs)\n",
    "brain.show_view(azimuth=190, elevation=70, distance=350, focalpoint=(0, 0, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlight a region on the brain\n",
    "\n",
    "* o highlight a region of the brain for analyses use the ``add_label`` method.\n",
    "* Labels are stored in the Freesurfer label directory from the `recon-all` for that subject\n",
    "* Labels can also be made following the [Freesurfer instructions](https://surfer.nmr.mgh.harvard.edu/fswiki/mri_vol2label)\n",
    "* In this example, Brodmann Area 44 is shown\n",
    "\n",
    "<div class=\"alert alert-info\"><h4>Note</h4><p>The MNE sample dataset contains only a subselection of the\n",
    "          Freesurfer labels created during the ``recon-all``.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain('sample', subjects_dir=subjects_dir, **brain_kwargs)\n",
    "brain.add_label('BA44', hemi='lh', color='green', borders=True)\n",
    "brain.show_view(azimuth=190, elevation=70, distance=350, focalpoint=(0, 0, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Include the Head in Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain('sample', subjects_dir=subjects_dir, **brain_kwargs)\n",
    "brain.add_head(alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Sensors Positions\n",
    "\n",
    "Put the sensors into context the data that generated the source time course (STC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain('sample', subjects_dir=subjects_dir, **brain_kwargs)\n",
    "evoked = mne.read_evokeds(op.join(sample_dir, 'sample_audvis-ave.fif'))[0]\n",
    "trans = mne.read_trans(op.join(sample_dir, 'sample_audvis_raw-trans.fif'))\n",
    "brain.add_sensors(evoked.info, trans)\n",
    "brain.show_view(distance=500)  # move back to show sensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add current dipoles\n",
    "\n",
    "Dipole modeling as in `tut-dipole-orientations` can be plotted on the\n",
    "brain as well.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "brain = mne.viz.Brain('sample', subjects_dir=subjects_dir, **brain_kwargs)\n",
    "dip = mne.read_dipole(op.join(sample_dir, 'sample_audvis_set1.dip'))\n",
    "cmap = plt.colormaps['YlOrRd']\n",
    "colors = [cmap(gof / dip.gof.max()) for gof in dip.gof]\n",
    "brain.add_dipole(dip, trans, colors=colors, scales=list(dip.amplitude * 1e8))\n",
    "brain.show_view(azimuth=-20, elevation=60, distance=300)\n",
    "img = brain.screenshot()  # for next section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a screenshot for exporting the brain image\n",
    "Also, we can a static image of the brain using ``screenshot`` (above),\n",
    "which will allow us to add a colorbar. This is useful for figures in\n",
    "publications.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(img)\n",
    "ax.axis('off')\n",
    "cax = fig.add_axes([0.9, 0.1, 0.05, 0.8])\n",
    "norm = Normalize(vmin=0, vmax=dip.gof.max())\n",
    "fig.colorbar(ScalarMappable(norm=norm, cmap=cmap), cax=cax)\n",
    "fig.suptitle('Dipole Fits Scaled by Amplitude and Colored by GOF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>\n",
    "Authors: SIONG Jong Hang \n",
    "         jonghang@gmail.com\n",
    "         Alex Rockhill\n",
    "         aprockhill@mailbox.org\n",
    "\n",
    "License: BSD-3-Clause\n",
    "</pre>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
